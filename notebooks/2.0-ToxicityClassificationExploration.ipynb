{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/konstfed/Documents/Study/PMLDL/PMLDL-TextDetoxification\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "os.chdir(os.path.dirname(os.path.abspath(\"./\")))\n",
    "print(os.getcwd())\n",
    "\n",
    "# SCRIPT_DIR = os.path.abspath(\".\")\n",
    "# print(SCRIPT_DIR)\n",
    "# sys.path.append(SCRIPT_DIR)\n",
    "# sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstfed/Documents/Study/PMLDL/PMLDL-TextDetoxification/toxic-venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/konstfed/Documents/Study/PMLDL/PMLDL-TextDetoxification/toxic-venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import yaml\n",
    "from addict import Dict\n",
    "\n",
    "from src.models import build_model\n",
    "from src.inference import ToxicClassificationPipeline, BertPipeline\n",
    "from src import preprocessing\n",
    "\n",
    "sys.modules['preprocessing'] = preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/sentence_toxic_cls/hard_labels.yaml\", \"r\") as f:\n",
    "    hard_config = Dict(yaml.safe_load(f))\n",
    "\n",
    "with open(\"configs/sentence_toxic_cls/soft_labels.yaml\", \"r\") as f:\n",
    "    soft_config = Dict(yaml.safe_load(f))\n",
    "\n",
    "with open(\"configs/sentence_toxic_cls/distilbert_inference.yaml\", \"r\") as f:\n",
    "    bert_config = Dict(yaml.safe_load(f))\n",
    "\n",
    "\n",
    "soft_cls = ToxicClassificationPipeline(soft_config) # BCEloss 0.45 on test\n",
    "hard_cls = ToxicClassificationPipeline(hard_config) # BCEloss 0.46 on test\n",
    "bert_cls = BertPipeline(bert_config) # BCEloss 0.05 on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts2analyze = [\n",
    "    \"You are moron\",\n",
    "    \"I'm so lonely and miserable. Life is so hard.\",\n",
    "    \"Ignore the dick\",\n",
    "    \"Whoever wrote this is a waste of space\",\n",
    "    \"I love cats\",\n",
    "    \"If you have not time to grade our works, why you think that we have enough time to write 7 pages of report with full-time work?\",\n",
    "    \"Also no bonus points for late grading. Half of works are not graded. The worst course at this moment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are moron\n",
      "soft label: tensor([0.5065]), hard_label: tensor([0.4943]), bert label: tensor([[0.7359]])\n",
      "\n",
      "I'm so lonely and miserable. Life is so hard.\n",
      "soft label: tensor([0.5045]), hard_label: tensor([0.4944]), bert label: tensor([[0.5495]])\n",
      "\n",
      "Ignore the dick\n",
      "soft label: tensor([0.5043]), hard_label: tensor([0.4969]), bert label: tensor([[0.7343]])\n",
      "\n",
      "Whoever wrote this is a waste of space\n",
      "soft label: tensor([0.5053]), hard_label: tensor([0.4941]), bert label: tensor([[0.5132]])\n",
      "\n",
      "I love cats\n",
      "soft label: tensor([0.5060]), hard_label: tensor([0.4938]), bert label: tensor([[0.5011]])\n",
      "\n",
      "If you have not time to grade our works, why you think that we have enough time to write 7 pages of report with full-time work?\n",
      "soft label: tensor([0.5051]), hard_label: tensor([0.4936]), bert label: tensor([[0.5027]])\n",
      "\n",
      "Also no bonus points for late grading. Half of works are not graded. The worst course at this moment\n",
      "soft label: tensor([0.5056]), hard_label: tensor([0.4946]), bert label: tensor([[0.5116]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(texts2analyze,start=1):\n",
    "    soft_res = soft_cls.forward(text)\n",
    "    hard_res = hard_cls.forward(text)\n",
    "    bert_res = bert_cls.forward(text)\n",
    "    print(text)\n",
    "    print(f\"soft label: {soft_res}, hard_label: {hard_res}, bert label: {bert_res}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
