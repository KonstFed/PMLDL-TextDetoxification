preprocessing:
  tokenizer:
    name: NLTK_tokenizer
    num_workers: 8
  text2vector:
    save_path: models/preprocessing/bow.obj
    name: WeightedBow
    minimum_freq: 100
    size: 2000
    verbose: True
model:
  name: LogisticRegression
  input_dim: 2000
training:
  train_val_test_ratio: [0.6, 0.2, 0.2]
  seed: 4000
  dataset: 
    name: BinaryToxicityLevelDataset
    data_path: "data/filtered.tsv"
    verbose: true
    threshold: 0.5
  dataloader:
    batch_size: 64
    num_workers: 7
  optimizer_args:
    name: torch.optim.Adam
#     lr: 0.1
  trainer_args:
    max_epochs: 3
    default_root_dir: "models/toxicity_log_regr"

