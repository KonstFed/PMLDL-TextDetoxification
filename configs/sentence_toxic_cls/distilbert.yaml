preprocessing:
  tokenizer:
    name: HugginFaceTokenizer
    model_name: distilbert-base-uncased
    padding: max_length
    truncation: True
model:
  name: DistilBert
  num_labels: 1
  model_name: distilbert-base-uncased
training:
  train_val_test_ratio: [0.6, 0.2, 0.2]
  seed: 4000
  dataset: 
    name: TransfosrmerDataset
    data_path: "data/filtered.tsv"
  dataloader:
    batch_size: 16
    num_workers: 7
  optimizer_args:
    lr: 0.00005
#     lr: 0.1
  trainer_args:
    max_epochs: 3
    default_root_dir: "models/toxicity_log_regr"

